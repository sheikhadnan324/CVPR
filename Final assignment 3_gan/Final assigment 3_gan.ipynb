{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnDnsj-R0mtw"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense \n",
        "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os \n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Wkiw5UK90sm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = data_path\n",
        "TRAIN_DATA_DIR = os.path.join(DATA_DIR, 'train')\n",
        "VALID_DATA_DIR = os.path.join(DATA_DIR, 'validation')\n",
        "TEST_DATA_DIR = os.path.join(DATA_DIR, 'test')\n"
      ],
      "metadata": {
        "id": "TTYeglwo0wfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 28\n",
        "CATEGORIES = ['0','1','2','3','4','5','6','7','8','9']\n",
        "   \n",
        "print(CATEGORIES)"
      ],
      "metadata": {
        "id": "OawClojn09RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width, height, channel = 28, 28, 3"
      ],
      "metadata": {
        "id": "QtePN1qj1CDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "i=0\n",
        "for c in CATEGORIES:  \n",
        "    path = os.path.join(TRAIN_DATA_DIR,c)\n",
        "    for img in os.listdir(path):\n",
        "        img_array = cv2.imread(os.path.join(path,img))\n",
        "        plt.subplot(10,10,i+1)\n",
        "        plt.imshow(img_array)\n",
        "        if i%10 == 0:\n",
        "            plt.ylabel(c)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        i += 1\n",
        "        if i%10 == 0:\n",
        "            break\n",
        "\n",
        "plt.tight_layout()        \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LRmR27DS1HoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "\n",
        "for c in CATEGORIES:\n",
        "    path = os.path.join(TRAIN_DATA_DIR, c) \n",
        "    class_num = CATEGORIES.index(c) \n",
        "    for img in tqdm(os.listdir(path)):\n",
        "        try:\n",
        "            img_array = cv2.imread(os.path.join(path, img))   \n",
        "            img_resized = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE)) \n",
        "            X.append([img_resized, class_num]) \n",
        "        except WException as e:\n",
        "            pass\n",
        "        \n",
        "print(len(X))"
      ],
      "metadata": {
        "id": "kTgUxBw31Lcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(X)"
      ],
      "metadata": {
        "id": "c46AOpyC1OyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "# X_train.shape\n",
        "for img, label in X:\n",
        "    X_train.append(img)\n",
        "    Y_train.append(label)\n",
        "    \n",
        "X_train = np.array(X_train).astype('float32').reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
        "Y_train = np.array(Y_train)\n",
        "\n",
        "print(f\"X_train= {X_train.shape} Y_train= {Y_train.shape}\")"
      ],
      "metadata": {
        "id": "iVbXOtXF1SDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = (X_train - 127.5) / 127.5"
      ],
      "metadata": {
        "id": "-PeU_nw61Uu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_optimizer = Adam(0.0001, 0.5)\n",
        "disc_optimizer = Adam(0.0002, 0.5)\n",
        "noise_dim = 100"
      ],
      "metadata": {
        "id": "ObRbbVuH1XKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buildGenerator():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(1024, input_dim=noise_dim))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    # model.add(Dense(2048, input_dim=noise_dim))\n",
        "    # model.add(BatchNormalization(momentum=0.8))\n",
        "    # model.add(Activation(\"relu\"))\n",
        "    \n",
        "    model.add(Dense(6272, input_dim=noise_dim))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    \n",
        "    model.add(Reshape((7, 7, 128)))\n",
        "    \n",
        "    model.add(UpSampling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (2, 2), padding='same', kernel_initializer=RandomNormal(0, 0.02)))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "\n",
        "    # model.add(UpSampling2D((2, 2)))\n",
        "    # model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer=RandomNormal(0, 0.02)))\n",
        "    # model.add(BatchNormalization(momentum=0.8))\n",
        "    # model.add(LeakyReLU(0.2))\n",
        "    \n",
        "    model.add(UpSampling2D((2, 2)))\n",
        "    model.add(Conv2D(3, (3, 3), padding='same', activation = \"tanh\", kernel_initializer=RandomNormal(0, 0.02)))\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "QGdfoalf1Zn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = buildGenerator()\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "qJarcMW71cJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buildDiscriminator():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv2D(64, (5, 5), strides=2, padding='same', kernel_initializer=RandomNormal(0, 0.02), input_shape=(28, 28, 3)))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    \n",
        "    model.add(Conv2D(128, (5, 5), strides=2, kernel_initializer=RandomNormal(0, 0.02)))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    \n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy', optimizer=disc_optimizer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "XBLnj44m1fGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = buildDiscriminator()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "9m8xzS8u1ik6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise = Input(shape=(noise_dim,))\n",
        "fake_data = generator(noise)\n",
        "discriminator.trainable = False\n",
        "output = discriminator(fake_data)\n",
        "gan = Model(noise, output)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=gen_optimizer)"
      ],
      "metadata": {
        "id": "b4EMHIjR1nfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan.summary()"
      ],
      "metadata": {
        "id": "rD9h9rPY1nnV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}